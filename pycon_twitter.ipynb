{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter user classification\n",
    "# Topic modeling and GloVe vectors in gensim\n",
    "<img src=\"images/gensim.png\">\n",
    "\n",
    "We will be developing a toy machine learning pipeline which can classify a twitter user into one of 8 categories based on the user's tweets.\n",
    "Following are the concepts we'll be exploring:\n",
    "- Bag of words\n",
    "- TF-IDF\n",
    "- Visualizing our data with topic models.\n",
    "- LDA model tuning with topic coherence\n",
    "- Dimensionality reduction with topic models\n",
    "- GloVe vectors for classification\n",
    "\n",
    "Through this tutorial, you will become comfortable with the gensim API and also learn how to do topic modeling effectively using gensim. There could be better ways of tuning certain topic models using other techniques however we will be using the newly released topic coherence pipeline implemented in gensim inspired from [this](http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf) paper by Roeder et al.\n",
    "### Requirements\n",
    "- [OPTIONAL] [python-twitter](https://python-twitter.readthedocs.io/en/latest/) (only for final function)\n",
    "- [Pre-trained stanford GloVe vectors for twitter](http://nlp.stanford.edu/data/glove.twitter.27B.zip)\n",
    "- gensim (latest development version preferred)\n",
    "- [OPTIONAL] [twitter app authentication](http://iag.me/socialmedia/how-to-create-a-twitter-app-in-8-easy-steps/) and hence a twitter account (only for final function where we'll do real-time classification) \n",
    "- scikit-learn\n",
    "- pandas\n",
    "- numpy\n",
    "- nltk with english stopwords\n",
    "-  At least 4 GB RAM preferred. Can use the smaller GloVe vector files if RAM is an issue as there are multiple GloVe vector files available.\n",
    "\n",
    "### Dataset\n",
    "I've already built a mini-dataset consisting of a `category->handle->tweets` mapping however this is just a toy dataset. A production level twitter classifier will most likely have many more categories with a lot more handles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import twitter\n",
    "except ImportError:\n",
    "    print(\"python-twitter not installed. Will not be able to do real-time classification\")\n",
    "import pickle\n",
    "import credentials  # You'll have to fill in the credentials in the credentials file here\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api = twitter.Api(**credentials.creds_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and exploring our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had created a function to get tweets category-wise to avoid rate limiting problems."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def getTweets(category_dict, category):\n",
    "    \"\"\"\n",
    "    Function to get the tweets for each handle in the dictionary in the particular category.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    category_dict: User category dictionary consisting of categories and user handles.\n",
    "    category: String. Name of the category.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    category_dict: Dictionary with the most recent 200 tweets of all user handles.\n",
    "    \"\"\"\n",
    "    for handle in category_dict[category]:\n",
    "        category_dict[category][handle] = api.GetUserTimeline(screen_name=handle, count=200)\n",
    "    return category_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had added all the handles I could think of in one category and then gathered the tweets. Not the best way to go about it! To add new handles to a category, simply use `api.GetUserTimeline(screen_name=handle)` and add that under the relevant category with the handle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pycon_dict = getTweets(pycon_dict, 'Business & CEOs')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pickle.dump(pycon_dict, open('pycon_dict.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can just load the pre-created pickle for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pycon_dict = pickle.load(open(\"data/pycon_dict.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which are the categories in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pycon_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each category contains a mix of benchmark twitter handles which can be magazines/channels and personalities tweeting about that category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pycon_dict['Music'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All categories have almost the same number of handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(['{}-{}'.format(cat, len(pycon_dict[cat].keys())) for cat in pycon_dict.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time for manual inspection\n",
    "This is an important step while dealing with textual data\n",
    "\n",
    "What do tweets from different categories look like? Can we spot any patterns or signals through manual inspection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pycon_dict['Business & CEOs']['XinfuCEOs'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pycon_dict['Music']['mtvmusic'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pycon_dict['Science']['NASA'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual inspection surely reveals some signal. We can see a marked difference between how typical tweets in the business, music and science category look like. Given some tweets from a category we should be able to classify accurately. The human mind is a pretty good classifier :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using 90% of the tweets (for each profile) for training and 10% for testing, i.e. a 90-10 split as mentioned in [this](http://snap.stanford.edu/soma2010/papers/soma2010_12.pdf) paper by Davison et al. Cross validation can and should be done however since our dataset is small we'll be skipping it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['message', 'category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [two-way](http://stackoverflow.com/questions/1456373/two-way-reverse-map) dictionary will help in creating a category mapping. I've already done this and we'll be using that mapping so that all of us have a uniform mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories_map = {0: u'Business & CEOs',\n",
    "                  1: u'Music',\n",
    "                  2: u'Entertainment',\n",
    "                  3: u'Fashion, Travel & Lifestyle',\n",
    "                  4: u'Sports',\n",
    "                  5: u'Tech',\n",
    "                  6: u'Politics',\n",
    "                  7: u'Science',\n",
    "                  u'Business & CEOs': 0,\n",
    "                  u'Entertainment': 2,\n",
    "                  u'Fashion, Travel & Lifestyle': 3,\n",
    "                  u'Music': 1,\n",
    "                  u'Politics': 6,\n",
    "                  u'Science': 7,\n",
    "                  u'Sports': 4,\n",
    "                  u'Tech': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataframes(pycon_dict):\n",
    "    \"\"\"\n",
    "    Function to get train and test dataframes (without any preprocessing).\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    pycon_dict: The twitter user dictionary being used.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    train, test: Train and test dataframes.\n",
    "    \"\"\"\n",
    "    train = pd.DataFrame(columns=columns)\n",
    "    test = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for category in pycon_dict:\n",
    "        for entity in pycon_dict[category]:\n",
    "            train_texts = []\n",
    "            test_texts = []\n",
    "            num_texts = len(pycon_dict[category][entity])  # To get number of tweets\n",
    "            train_indices = np.random.choice(num_texts, int(0.9 * num_texts), replace=False)  # Random selection\n",
    "            test_indices = [i for i in range(num_texts) if i not in train_indices]  # Rest go into test set\n",
    "            train_texts.extend(pycon_dict[category][entity][i].text for i in train_indices)  # Add to train texts\n",
    "            test_texts.extend(pycon_dict[category][entity][i].text for i in test_indices)  # Add to test texts\n",
    "            #### Create train dataframe ####\n",
    "            train_texts = ' '.join(train_texts)\n",
    "            df_train = pd.DataFrame([[train_texts, categories_map[category]]], columns=columns)\n",
    "            train = train.append(df_train, ignore_index=True)\n",
    "            #### Create test dataframe ####\n",
    "            test_texts = ' '.join(test_texts)\n",
    "            df_test = pd.DataFrame([[test_texts, categories_map[category]]], columns=columns)\n",
    "            test = test.append(df_test, ignore_index=True)\n",
    "            \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing our data. Remember: Garbage in, garbage out\n",
    "    NLP is 80% preprocessing\n",
    "                        - Lev Konstantinovskiy\n",
    "Preprocessing is probably the single most important step in producing good topic models which give human interpretable topics. Do take some time to study the preprocessor well because we'll be using the same preprocessor for the tasks later on for classification using Bag of words and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords  # for using english stopwords\n",
    "from gensim.models.phrases import Phrases\n",
    "from gensim.utils import deaccent, decode_htmlentities, lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the steps we'll be taking to preprocess a user profile, i.e. a space seperated collection of at most 200 most recent tweets of the profile:\n",
    "1. Decode html entities. eg. \"AT`&`amp;T\" will become \"AT&T\"\n",
    "2. Deaccent. Eg:\n",
    "    ```\n",
    "    >>> deaccent(\"Šéf chomutovských komunistů dostal poštou bílý prášek\")\n",
    "    u'Sef chomutovskych komunistu dostal postou bily prasek'\n",
    "    ```\n",
    "3. Remove links.\n",
    "4. Remove any user mentions (__@name__). This could maybe be skipped as user mentions can also provide signal. However we'll be removing them for this tutorial.\n",
    "5. Lemmatize and remove stopwords. Lemmatization is preferred over stemming here because lemmatization retains readability of the words which is important in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_text(tweet):\n",
    "    \"\"\"\n",
    "    Function to process an aggregated user profile. This does the following:\n",
    "    1. Decode html entities. eg. \"AT&amp;T\" will become \"AT&T\"\n",
    "    2. Deaccent\n",
    "    3. Remove links.\n",
    "    4. Remove any user mentions (@name).\n",
    "    5. Lemmatize and remove stopwords.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    text : String. If train_texts is a list of tweets, ' '.join and pass\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    text : preprocessed (tokenized) tweet.\n",
    "    \"\"\"\n",
    "    tweet = decode_htmlentities(tweet)\n",
    "    tweet = deaccent(tweet)\n",
    "    tweet = tweet.encode('ascii', 'ignore')  # To prevent UnicodeDecodeErrors later on\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)  # Step 3\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)  # Step 4\n",
    "    tweet = tweet.split()\n",
    "    tweet = lemmatize(' '.join(tweet), re.compile('(NN)'), stopwords=stops, min_length=3, max_length=15)\n",
    "    tweet = [word.split('/')[0] for word in tweet]\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_text('Tropical House Lives On At Electric Zoo :) https://t.co/lUpLIpWg3H by @_davidturner_: https://t.co/NI3bq2k8am')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preprocessing our train, test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = get_dataframes(pycon_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our function does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_text(train['message'][0])[100:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply function to all tweets in our training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_texts = train['message'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram collocation can detect words which frequently occur together and know whether they are in fact the same entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram = Phrases(train_texts)  # For collocation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram['hillary', 'clinton']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the bigram collocation has figured out that the words 'hillary' and 'clinton' refer to the same entity that is 'Hillary Clinton' the politician."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_texts = [bigram[profile] for profile in train_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice the other bigram collocations below for the sports category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_texts[100][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_texts = test['message'].apply(preprocess_text)\n",
    "test_texts = [bigram[message] for message in test_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up helper functions for classification evaluation\n",
    "It is important to choose an evaluation metric to compare our models. We will choose accuracy here however other metrics such as F-Measure can also be used depending on the use-case of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_tags = pycon_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = train['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(my_tags))\n",
    "    target_names = my_tags\n",
    "    plt.xticks(tick_marks, target_names, rotation=90)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_prediction(predictions, target, title=\"Confusion matrix\"):\n",
    "    print('accuracy %s' % accuracy_score(target, predictions))\n",
    "    cm = confusion_matrix(target, predictions)\n",
    "    print('confusion matrix\\n %s' % cm)\n",
    "    print('(row=expected, col=predicted)')\n",
    "    \n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plot_confusion_matrix(cm_normalized, title + ' Normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_influential_words(clf, vectorizer, category_index=0, num_words=10):\n",
    "    features = vectorizer.get_feature_names()\n",
    "    max_coef = sorted(enumerate(clf.coef_[category_index]), key=lambda x:x[1], reverse=True)\n",
    "    return [features[x[0]] for x in max_coef[:num_words]]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build our first classification model\n",
    "__Note__: We will be using `LogisticRegression` throughout this tutorial. I would also encourage you to try out the new `MLPClassifier` released as part of `scikit-learn 0.18`. This uses a neural network for classification and is a very powerful tool for learning complex non-linear functions.\n",
    "\n",
    "# Bag of words with LogisticRegression\n",
    "It sometimes important in any machine learning task to set up a baseline model in as little time as possible. This can help us gauge how much better our ideal model should be. It can also help us find out the areas where we need to work on to make our model better. Would bringing in more data help? Would making our preprocessing better help? Such questions can be answered more accurately. There are many ways to find out the answers to these questions however they lie of of scope for this tutorial\n",
    "\n",
    "We will be using bag of words first as it is the simplest document feature which is available. It is simply a word occurence matrix across all the words and all the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll only take the most significant 5000 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_count_features = count_vectorizer.fit_transform(' '.join(text) for text in train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_count = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_count = clf_count.fit(train_count_features, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_count_features = count_vectorizer.transform(' '.join(text) for text in test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf_count.predict(test_count_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_prediction(predictions, test['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greater than 90% accuracy is great for our first model!\n",
    "\n",
    "__Why did it work__? Twitter benchmark users of any particular category tweet in a very distinct way. As we saw above, users in the \"Music\" category are more likely to use words like \"performance\" or \"album\" more. Similarly users in the \"Politics\" category tend to use words like \"policy\" more. Bag of words can catch this quite brilliantly! We can see evidence of this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_influential_words(clf_count, count_vectorizer, category_index=7)  # Top words for science category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) with LogisticRegression\n",
    "This is a slightly more advanced method than bag of words. Bag of words needs good preprocessing more than TF-IDF as it is a raw count. However TF-IDF can reduce the weight for highly occuring terms such as 'the' by dividing by normalizing it with the number of documents it occurs in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_tfidf_features = tfidf_vectorizer.fit_transform(' '.join(text) for text in train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_tfidf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_tfidf = clf_tfidf.fit(train_tfidf_features, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_tfidf_features = tfidf_vectorizer.transform(' '.join(text) for text in test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf_tfidf.predict(test_tfidf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_prediction(predictions, test['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: What are the most influential words from this model in the politics category?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even this model gives us a wonderful accuracy!\n",
    "\n",
    "__However let's try some more methods__. First we will do some topic modeling. After all the package we will be using is called \"Gensim-Topic Modeling for Humans\"! Topic modeling can help find hidden structure in our data and thus is very useful in visualizing our dataset. It can in turn also be used for classification and dimensionality reduction among many of it's other uses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do some topic modelling\n",
    "Essentially we're trying to find out the topics of the tweets which the user is tweeting about. Since topic models come up with topic distributions, they can probably help us in this task.\n",
    "\n",
    "Let's see if we can use topic models to find some hidden structure in our data first!\n",
    "\n",
    "### Setting up our standard gensim corpus\n",
    "You can refer to the short tutorial [here](https://radimrehurek.com/gensim/tut1.html) for reference as to how a standard gensim corpus is set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = Dictionary(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in train_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [LSI](https://radimrehurek.com/gensim/models/lsimodel.html) (Latent Semantic Indexing)\n",
    "LSI uses Singular Value Decomposition (SVD) for topic modeling. It can rank topics automatically but needs the `num_topics` parameter to be entered for the number of latent dimensions requested. There is currently an open [issue](https://github.com/RaRe-Technologies/gensim/issues/28) in gensim where an automatic number of topics \"chooser\" has been proposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import LsiModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsim = LsiModel(corpus=corpus, num_topics=100, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsim.show_topics(num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsimtopics = lsim.show_topics(formatted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [HDP](https://radimrehurek.com/gensim/models/hdpmodel.html) (Hierarchical Dirichlet Process)\n",
    "An HDP model is fully unsupervised. It can also determine the ideal number of topics through posterior inference. This property of HDP is particularly useful when in the \"online\" mode where the number of documents keep streaming and hence the number of topics becomes hard to determine before-hand as in LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import HdpModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdpm = HdpModel(corpus=corpus, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdpm.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDP surely comes up with better, more human interpretable topics as we can see. There are topics which clearly talk about sports, others which only have words related to politics or some which relate to travel. As we saw above in LSI, the topics were a bit mixed up. HDP doesn't seem to mix it up as much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdpmtopics = hdpm.show_topics(num_topics=-1, num_words=10, formatted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [LDA](https://radimrehurek.com/gensim/models/ldamodel.html) (Latent Dirichlet Allocation)\n",
    "This is one the most popular topic modeling algorithms today. It is a generative model in that it assumes each document is a mixture of topics and in turn, each topic is a mixture of words. To understand it better you can watch [this](https://www.youtube.com/watch?v=DDq3OVp9dNA) lecture by David Blei.\n",
    "<img src=\"images/blei_news.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldam = LdaModel(corpus=corpus, num_topics=100, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldam.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LdaModel` also comes up with decent topics. We can decipher some topics by the word distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamtopics = ldam.show_topics(num_topics=-1, formatted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Coherence\n",
    "<img src='images/pipeline.png'>\n",
    "Topic coherence is a way to quantify the human interpretability of the topics. Simply enter the __topics 't'__ and you get __coherence value 'c'__ as the output! The topic coherence pipeline recently got merged into gensim which was based on [this](http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf) paper by Roeder et al.\n",
    "\n",
    "This is a great way to compare individual topics and can be extended to comparing different topic models as well. We will be doing this later on in this tutorial.\n",
    "\n",
    "To know more about topic coherence you can read my blog [here](https://rare-technologies.com/what-is-topic-coherence/) where I have to tried to give an introductory explanation of how topic coherence works.\n",
    "\n",
    "### Finding optimal number of topics\n",
    "As we saw above, `LdaModel` requires the number of topics to be entered for fitting it. This is one of the problem of LDA as knowing the number of topics beforehand can be a challenging task especially in an online setting. Traditionally, perplexity has been used to find out the optimum number of topics. We will be using topic coherence instead. The logic is pretty simple in that: \"Let's select the number of topics which we can understand easily\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE = 6  # base number of topics for graph evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_graph(dictionary, corpus, texts, limit):\n",
    "    \"\"\"\n",
    "    Function to display num_topics - LDA graph using c_v coherence\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    limit : topic limit\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    lm_list : List of LDA topic models\n",
    "    \"\"\"\n",
    "    if limit < BASE:\n",
    "        raise ValueError(\"Please enter limit > %d. You entered %d\" % (BASE, limit))\n",
    "    c_v = []\n",
    "    lm_list = []\n",
    "    for num_topics in range(BASE, limit):\n",
    "        lm = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        lm_list.append(lm)\n",
    "        cm = CoherenceModel(model=lm, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        c_v.append(cm.get_coherence())\n",
    "        \n",
    "    # Show graph\n",
    "    x = range(6, limit)\n",
    "    plt.plot(x, c_v)\n",
    "    plt.xlabel(\"num_topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"c_v\"), loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    return lm_list, c_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iteratively train LdaModels for different number of topics ranging from 6 to 15. Topics lesser than 6 might not make sense however we should be getting the ideal value around 8 as the number of categories we have are 8.\n",
    "\n",
    "__Warning__: Can take quite long to compute. If you want to reduce the amount of time taken here, you can reduce the limit or better, change the coherence algorithm to `u_mass` instead. However it has been experimentally proven that `c_v` correlates best with human interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lm_list, c_v = evaluate_graph(dictionary, corpus, train_texts, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldam_tc = lm_list[np.argmax(c_v)]  # Select the LdaModel corresponding to the best coherence value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldam_tc.show_topics(num_topics=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldam_tctopics = ldam_tc.show_topics(num_topics=-1, formatted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA as LSI\n",
    "As we saw above, LSI can automatically rank topics. We can actually do the same with LDA also by making it work with the topic coherence pipeline. We rank individual topics based on their human interpretability.\n",
    "\n",
    "We will be going one step further here and making a new LDA model by using only the best topics from the first LDA model. An \"LDA migration\" of sorts! This can be done by selecting the `alphas` and `betas` corresponding to only the best topics from the first LDA model and transferring them onto the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ret_top_model(num_topics):\n",
    "    \"\"\"\n",
    "    Since LDAmodel is a probabilistic model, it comes up different topics each time we run it. To control the\n",
    "    quality of the topic model we produce, we can create another topic model from only the most coherent n topics\n",
    "    from the LDAmodel.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    num_topics: Number of top topics for new LdaModel.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    refined_lm: Final evaluated topic model\n",
    "    top_topics: ranked topics in decreasing order. List of tuples\n",
    "    \"\"\"\n",
    "    lm = LdaModel(corpus=corpus, id2word=dictionary)\n",
    "    coherence_values = {}\n",
    "    doc = []\n",
    "    for n, topic in lm.show_topics(num_topics=-1, formatted=False):\n",
    "        topic = [word for word, _ in topic]\n",
    "        cm = CoherenceModel(topics=[topic], texts=train_texts, dictionary=dictionary)\n",
    "        coherence_values[n] = cm.get_coherence()\n",
    "    top_topics = sorted(coherence_values.items(), key=operator.itemgetter(1), reverse=True)[:num_topics]\n",
    "    top_topics = [t for t, c in top_topics]\n",
    "    alpha = lm.alpha[top_topics]\n",
    "    beta = lm.expElogbeta[top_topics, :]\n",
    "    refined_lm = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, alpha=alpha)\n",
    "    refined_lm.expElogbeta[:] = beta\n",
    "    return refined_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Warning__: Can take some time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lda_lsim = ret_top_model(BASE + np.argmax(c_v))  # Using the value we found above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_lsim.show_topics(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDP model still seems like the best one yet...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_lsimtopics = lda_lsim.show_topics(num_topics=-1, formatted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transfer out HDP model into an LDA model. We can do these by copying over the corresponding alphas and betas into the LDA model. This will also help us calculate topic inferences easily if this turns out to be the best LDA model so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha, beta = hdpm.hdp_to_lda()\n",
    "num_topics = len(hdpmtopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lda_hdp = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, alpha=alpha)\n",
    "lda_hdp.expElogbeta[:] = beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating all topic models\n",
    "Finally, we will be using the topic coherence pipeline to compare all the topic models we have created so far. Till now we have only been qualitatively comparing the models. The topic coherence pipeline allows us to quantitatively compare the different topic models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsimtopics = [[word for word, prob in topic] for topicid, topic in lsimtopics]\n",
    "hdpmtopics = [[word for word, prob in topic] for topicid, topic in hdpmtopics]\n",
    "ldamtopics = [[word for word, prob in topic] for topicid, topic in ldamtopics]\n",
    "ldam_tctopics = [[word for word, prob in topic] for topicid, topic in ldam_tctopics]\n",
    "lda_lsimtopics = [[word for word, prob in topic] for topicid, topic in lda_lsimtopics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lsi_coherence = CoherenceModel(topics=lsimtopics, texts=train_texts, dictionary=dictionary, window_size=110).get_coherence()\n",
    "hdp_coherence = CoherenceModel(topics=hdpmtopics, texts=train_texts, dictionary=dictionary, window_size=110).get_coherence()\n",
    "lda_coherence = CoherenceModel(topics=ldamtopics, texts=train_texts, dictionary=dictionary, window_size=110).get_coherence()\n",
    "lm_coherence = CoherenceModel(topics=ldam_tctopics, texts=train_texts, dictionary=dictionary, window_size=110).get_coherence()\n",
    "lda_lsi_coherence = CoherenceModel(topics=lda_lsimtopics, texts=train_texts, dictionary=dictionary, window_size=110).get_coherence()\n",
    "lda_hdp_coherence = CoherenceModel(model=lda_hdp, texts=train_texts, dictionary=dictionary).get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_bar_graph(coherences, indices):\n",
    "    \"\"\"\n",
    "    Function to plot bar graph.\n",
    "    \n",
    "    coherences: list of coherence values\n",
    "    indices: Indices to be used to mark bars. Length of this and coherences should be equal.\n",
    "    \"\"\"\n",
    "    assert len(coherences) == len(indices)\n",
    "    n = len(coherences)\n",
    "    x = np.arange(n)\n",
    "    plt.bar(x, coherences, width=0.2, tick_label=indices, align='center')\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Coherence Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_bar_graph([lsi_coherence, hdp_coherence, lda_coherence, lm_coherence, lda_lsi_coherence, lda_hdp_coherence],\n",
    "                   ['LSI', 'HDP', 'LDA', 'LDA_TC', 'LDA_LSI', 'LDA_HDP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our intuition was correct! HDP model turned out to be the best one and the transferred HDP model turned out to be the best LDA model. I would have liked our optimal topics and lda_lsi to perform better but we can be happy that it at least performs better than vanilla LDA!\n",
    "\n",
    "__DO REMEMBER__ that these values and topic models only correspond to this dataset and can vary accross different datasets. In fact since LDA models are probabilistic, they can vary a lot across runs too! We could have done better in LDA tuning however this was a tutorial on how topic coherence in particular can be used for LDA tuning. \n",
    "I have observed that HDP models generally perform better when each `text` within `texts` has a lot of tokens. You will notice that the comparison turned out to be very different in my [news classification notebook](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/gensim_news_classification.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can infer topic distributions from individual word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_hdp[dictionary.doc2bow(['jimmy', 'fallon', 'entertainment'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_hdp.show_topic(60, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA for dimensionality reduction\n",
    "In this tutorial we will be using our best LDA model from above for dimensionality reduction. When we use LDA for inference it gives large probabilities for some topics but negligible for the others. This is how it looks like:\n",
    "<img src='images/inference.jpg'>\n",
    "<center> _Image taken from Blei's video on LDA_ </center>\n",
    "\n",
    "__This is the pipeline we're following for LDA dimensionality reduction__ (wanted to see how well I can use the pencil in gimp):\n",
    "<img src='images/lda_dim_red.png'>\n",
    "P, B = Preprocessing, bigram collocation\n",
    "\n",
    "LDA = LDA model for inference\n",
    "\n",
    "CLF = Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lda_features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above in the graph, LDA inference yields positive values for only some topics and negligible values for the others. We can assume them to be 0 to create our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for message in train_texts:\n",
    "    features = np.zeros(shape=(1, num_topics))\n",
    "    inference = lda_hdp[dictionary.doc2bow(message)]\n",
    "    for tid, val in inference:\n",
    "        features[:, tid] = val\n",
    "    features = pd.DataFrame(features)\n",
    "    train_lda_features = train_lda_features.append(features, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_lda_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_lda_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_lda = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_lda = clf_lda.fit(train_lda_features, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_lda_features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for message in test_texts:\n",
    "    features = np.zeros(shape=(1, num_topics))\n",
    "    inference = lda_hdp[dictionary.doc2bow(message)]\n",
    "    for tid, val in inference:\n",
    "        features[:, tid] = val\n",
    "    features = pd.DataFrame(features)\n",
    "    test_lda_features = test_lda_features.append(features, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_lda_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = clf_lda.predict(test_lda_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_prediction(predictions, test['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: Plug in our HDP model above instead of LDA model and see what's the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out, our TF-IDF and bag of words based models outperform this method. However no gensim tutorial is complete without word embeddings. Let's try word embeddings now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec can make your heart skip a gram\n",
    "Well this is not really word2vec. We're just loading pre-trained twitter GloVe vectors. GloVe produces word embeddings in a different way than word2vec. GloVe uses a count-based model to learn word embeddings whereas word2vec tries to learn a \"predictive\" model by using different algorithms such as skip-gram or CBOW.\n",
    "\n",
    "We will be using twitter pre-trained GloVe vectors on twitter. We can convert them into word2vec vectors by just running [this](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/scripts/glove2word2vec.py) script present in gensim. I have used the 50d vectors however you are free to use the larger embeddings depending on the RAM you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wv = Word2Vec.load_word2vec_format(\"/home/devashish/Downloads/GloVes/wv.twitter.27B.50d.txt\",\n",
    "                                   binary=False)  # To use C text format\n",
    "wv.init_sims(replace=True)  # To decrease RAM usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wv.most_similar(positive=['arsenal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this task our preprocessing will be different\n",
    "Preprocessing taken from [stanford twitter-preprocessor](http://nlp.stanford.edu/projects/glove/preprocess-twitter.rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "exclude = string.punctuation\n",
    "exclude = re.sub('<|>', '', exclude)  # To keep our <tags> intact\n",
    "exclude = set(exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "preprocess-twitter.py\n",
    "python preprocess-twitter.py \"Some random text with #hashtags, @mentions and http://t.co/kdjfkdjf (links). :)\"\n",
    "Script for preprocessing tweets by Romain Paulus\n",
    "with small modifications by Jeffrey Pennington\n",
    "with translation to Python by Motoki Wu\n",
    "Translation of Ruby script to create features for GloVe vectors for Twitter data.\n",
    "http://nlp.stanford.edu/projects/glove/preprocess-twitter.rb\n",
    "\"\"\"\n",
    "\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \"<hashtag> {} <allcaps>\".format(hashtag_body)\n",
    "    else:\n",
    "        result = \" \".join([\"<hashtag>\"] + re.split(r\"(?=[A-Z])\", hashtag_body, flags=FLAGS))\n",
    "    return result\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower() + \" <allcaps> \"\n",
    "\n",
    "\n",
    "def preprocess_tweet(text):\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = r\"[8:=;]\"\n",
    "    nose = r\"['`\\-]?\"\n",
    "\n",
    "    # function so code less repetitive\n",
    "    def re_sub(pattern, repl):\n",
    "        return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "    text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "    text = re_sub(r\"/\",\" / \")\n",
    "    text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "    text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "    text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "    text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "    text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "    text = re_sub(r\"<3\",\"<heart>\")\n",
    "    text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \" <number> \")\n",
    "    text = re_sub(r\"#\\S+\", hashtag)\n",
    "    text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "    text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "\n",
    "    ## -- I just don't understand why the Ruby script adds <allcaps> to everything so I limited the selection.\n",
    "    # text = re_sub(r\"([^a-z0-9()<>'`\\-]){2,}\", allcaps)\n",
    "    text = re_sub(r\"([A-Z]){2,}\", allcaps)\n",
    "    \n",
    "    text = ''.join(ch for ch in text if ch not in exclude)  # Remove punctuation\n",
    "\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g2v_tokenize_tweet(text):\n",
    "    text = text.encode('ascii', 'ignore')  # Deal with UnicodeDecodeErrors\n",
    "    text = preprocess_tweet(text)\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vector Averaging\n",
    "To get a vector for a document, we simply average it's word vectors. As suggested in [this](https://www.youtube.com/watch?v=7gTjYwiaJiU) video by Mike Tamir, the word averaging results to some kind of a unique word summarizing the whole document in one word. Eg all words in a book 'A tale of two cities' would probably add up to 'class-struggle'.\n",
    "<img src='images/word_avg.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code from \"Movie plots by genre\" by Lev Konstantinovskiy:\n",
    "# https://github.com/RaRe-Technologies/movie-plots-by-genre\n",
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.layer_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, review) for review in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_tokenized = train.apply(lambda t: g2v_tokenize_tweet(t['message']), axis=1).values\n",
    "test_tokenized = test.apply(lambda t: g2v_tokenize_tweet(t['message']), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_g2v = LogisticRegression()\n",
    "clf_g2v = clf_g2v.fit(X_train_word_average, train['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf_g2v.predict(X_test_word_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_prediction(predictions, test['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turned out to be pretty disappointing :( Probably word averaging doesn't work too well for tweets. This classifies most categories as \"Business and CEOs\" for some reason.\n",
    "\n",
    "__Things to try__: We can tweak our preprocessing here. Probably use our previous preprocessor. Can also use a neural network based MLPClassifier instead of logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can use the function below for user classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tweets(handle):\n",
    "    \"\"\"\n",
    "    Function to return user profile.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    handle: Twitter handle\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    tweets: space seperated list of tweets\n",
    "    \"\"\"\n",
    "    tweets = api.GetUserTimeline(screen_name=handle, count=200)\n",
    "    tweets = [tweet.text for tweet in tweets]\n",
    "    return ' '.join(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_handle(handle, vectorizer=None, clf=None, g2v_or_lda=None):\n",
    "    \"\"\"\n",
    "    Function to classify handle. Vectorizer need not be\n",
    "    provided if g2v_or_lda is being used. g2v_or_lda can be:\n",
    "        'g2v' for classification with glove word averaging\n",
    "        'lda' for classification with LDA inference\n",
    "        'None' for classification with standard preprocessor and vectorizer\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    handle: Twitter handle of user to classify\n",
    "    vectorizer: Vectorizer (pre-trained) to be used\n",
    "    clf: Classifier (pre-trained) to be used\n",
    "    g2v_or_lda: 'g2v', 'lda' or 'None' depending on which \"mode\" you want to use\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    category: Classified category\n",
    "    \"\"\"\n",
    "    if clf is None:\n",
    "        raise Exception('Classifier has to be provided')\n",
    "    if vectorizer is None and g2v_or_lda is None:\n",
    "        raise Exception('Vectorizer should be provided if glove'\n",
    "                        ' or LDA classification is not being used')\n",
    "    profile = get_tweets(handle)\n",
    "    if g2v_or_lda is None:\n",
    "        profile = preprocess_text(profile)\n",
    "        profile = bigram[profile]\n",
    "        features = vectorizer.transform([' '.join(profile)])\n",
    "    else:\n",
    "        if g2v_or_lda == 'g2v':\n",
    "            profile = g2v_tokenize_tweet(profile)\n",
    "            features = word_averaging_list(wv, profile)\n",
    "        elif g2v_or_lda == 'lda':\n",
    "            features = np.zeros(shape=(1, num_topics))\n",
    "            inference = lda_hdp[dictionary.doc2bow(message)]\n",
    "            for tid, val in inference:\n",
    "                features[:, tid] = val\n",
    "    category = clf.predict(features)\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    pred = pred_handle('chelseafc', vectorizer=count_vectorizer, clf=clf_count, g2v_or_lda=None)[0]\n",
    "except:\n",
    "    print(\"Please check whether python-twitter is installed. If yes, please check\"\n",
    "          \" whether credentials are stored correctly.\")\n",
    "print categories_map[pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Please note that the results for these techniques apply to this particular dataset only__\n",
    "\n",
    "GloVe and word embeddings are a very powerful technique to do complex NLP tasks. Do watch [this](https://www.youtube.com/watch?v=vkfXBGnDplQ) video by Chris Moody to see some of the applications of word2vec outside of text processing.\n",
    "\n",
    "You can try other techniques too such as Doc2Vec, word mover's distance (WMD) etc. for exploring more techniques to working with text data. Do check out [this](https://github.com/RaRe-Technologies/movie-plots-by-genre/blob/master/ipynb_with_output/Document%20classification%20with%20word%20embeddings%20tutorial%20-%20with%20output.ipynb) notebook by Lev Konstantinovskiy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography\n",
    "Do have a look at the following resources I used for making this tutorial:\n",
    "- [Movie plots by genre by Lev Konstantinovskiy](https://github.com/RaRe-Technologies/movie-plots-by-genre/blob/master/ipynb_with_output/Document%20classification%20with%20word%20embeddings%20tutorial%20-%20with%20output.ipynb)\n",
    "- [Topic coherence pipeline paper by Roeder et al](svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf)\n",
    "- [Original LDA paper by Blei et al](https://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf)\n",
    "- [Online LDA paper by Blei et al](https://www.cs.princeton.edu/~blei/papers/HoffmanBleiBach2010b.pdf)\n",
    "- [Empirical study of topic modeling in Twitter by Davison et al](http://snap.stanford.edu/soma2010/papers/soma2010_12.pdf)\n",
    "- [Machine learning approach to twitter user classification by Pennacchiotti et al](https://www.google.co.in/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0ahUKEwjHiN7E8svPAhUKPo8KHaY3CsUQFggiMAA&url=https%3A%2F%2Fwww.aaai.org%2Focs%2Findex.php%2FICWSM%2FICWSM11%2Fpaper%2Fdownload%2F2886%2F3262&usg=AFQjCNE7NxTUl11QpN6GA7qj6_NNK0tjqw&sig2=LXSszb8tQN00sej6yr-I5w)\n",
    "- [Stanford GloVe project](http://nlp.stanford.edu/projects/glove/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
